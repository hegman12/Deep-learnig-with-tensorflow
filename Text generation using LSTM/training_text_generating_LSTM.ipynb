{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('single_sherlock_ids.txt','r',encoding='utf-8') as f:\n",
    "    data=f.read().strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"C:\\\\MLDatabases\\\\JNotebooks\\\\word embedding training\\\\gutenburg_dict_reversed_500000.txt\",'r',encoding='utf-8') as f:\n",
    "    r_dict=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "embedding_dim=100\n",
    "num_layers=2\n",
    "time_steps=50\n",
    "state_size=101\n",
    "out_size=500000\n",
    "vocab_size=out_size\n",
    "num_sampled=64\n",
    "epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em=np.load('C:\\\\MLDatabases\\\\JNotebooks\\\\word embedding training\\\\normalized_embed.npy',mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(state_size,drpout):\n",
    "    return tf.nn.rnn_cell.DropoutWrapper(tf.nn.rnn_cell.LSTMCell(state_size),output_keep_prob=drpout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(10)\n",
    "np.random.seed(10)\n",
    "tf.reset_default_graph()\n",
    "def graph():\n",
    "    \n",
    "    with tf.device('/device:GPU:0'):\n",
    "        const_init=tf.placeholder(tf.float32,shape=(vocab_size,embedding_dim),name=\"ci\")\n",
    "        var_init=tf.truncated_normal_initializer(dtype=tf.float32,mean=0,stddev=0.003)\n",
    "        bias_init=tf.truncated_normal_initializer(dtype=tf.float32,mean=0,stddev=1)\n",
    "\n",
    "        softmax_var_init=tf.truncated_normal_initializer(dtype=tf.float32,mean=0,stddev=0.003)\n",
    "        softmax_bias_init=tf.truncated_normal_initializer(dtype=tf.float32,mean=0,stddev=1)\n",
    "\n",
    "        x=tf.placeholder(tf.int32,shape=(None,None),name=\"x\")\n",
    "        y=tf.placeholder(tf.int32,shape=(None,None),name='y')\n",
    "        batchsize=tf.placeholder(tf.int32,shape=(),name=\"batchsize\")\n",
    "\n",
    "        matrix=tf.get_variable(\"matrix\",initializer=const_init,trainable=False)\n",
    "        w=tf.get_variable(\"w\",initializer=var_init,trainable=True,shape=(state_size,embedding_dim))\n",
    "        b=tf.get_variable(\"b\",initializer=bias_init,trainable=True,shape=(embedding_dim,))\n",
    "\n",
    "        softmax_weight=tf.get_variable(\"softmax_weight\",initializer=softmax_var_init,trainable=True,shape=(vocab_size,embedding_dim))\n",
    "        softmax_bias=tf.get_variable(\"softmax_bias\",initializer=softmax_bias_init,trainable=True,shape=(vocab_size,))\n",
    "\n",
    "        x_flat=tf.reshape(x,[1,-1])\n",
    "        xo=tf.nn.embedding_lookup(matrix,x_flat)\n",
    "        xo=tf.reshape(xo,[batchsize,-1,embedding_dim])\n",
    "\n",
    "        drpout=tf.placeholder(tf.float32,name='drpout')\n",
    "        lr=tf.placeholder(tf.float32,name='lr')\n",
    "\n",
    "        cell_state=tf.placeholder(tf.float32,shape=(num_layers,None,None),name='cell_state')\n",
    "        hidden_state=tf.placeholder(tf.float32,shape=(num_layers,None,None),name='hidden_state')\n",
    "\n",
    "        init_state=   tuple(tf.nn.rnn_cell.LSTMStateTuple(c,h) for (c,h) in zip(tf.unstack(cell_state,name=\"cell_state\"),tf.unstack(hidden_state,name=\"hidden_state\")))\n",
    "        print(init_state)\n",
    "        multi_cell=tf.nn.rnn_cell.MultiRNNCell([lstm_cell(state_size,drpout) for _ in range(num_layers)])\n",
    "\n",
    "        rnn_out,final_state=tf.nn.dynamic_rnn(cell=multi_cell,initial_state=init_state,inputs=xo)\n",
    "\n",
    "        rnn_out=tf.reshape(rnn_out,[-1,state_size])\n",
    "\n",
    "        linear_out= tf.add(tf.matmul(rnn_out,w,name='matmul_op'),b,name='bias_add_op')\n",
    "        linear_out=tf.nn.dropout(x=linear_out,keep_prob=drpout)\n",
    "        val_logits=tf.add(tf.matmul(linear_out,tf.transpose(softmax_weight)),softmax_bias)\n",
    "        print(val_logits)\n",
    "        \n",
    "        with tf.device('/device:CPU:0'):\n",
    "            val_logits=tf.nn.softmax(val_logits,axis=-1)            \n",
    "            val_logits=tf.identity(val_logits,name=\"val_logits\")\n",
    "        print(val_logits)\n",
    "        labels= tf.cast(tf.reshape(y,[-1,1]),tf.int64)\n",
    "\n",
    "        with tf.device('/device:CPU:0'):\n",
    "            loss=tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=softmax_weight,biases=softmax_bias,inputs=linear_out,labels=labels,num_classes=vocab_size,num_sampled=num_sampled,partition_strategy=\"div\",remove_accidental_hits=True))\n",
    "            train_step=tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "    return x,y,lr,drpout,loss,train_step,cell_state,hidden_state,final_state,val_logits,batchsize,const_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LSTMStateTuple(c=<tf.Tensor 'cell_state_1:0' shape=(?, ?) dtype=float32>, h=<tf.Tensor 'hidden_state_1:0' shape=(?, ?) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'cell_state_1:1' shape=(?, ?) dtype=float32>, h=<tf.Tensor 'hidden_state_1:1' shape=(?, ?) dtype=float32>))\n",
      "Tensor(\"Add:0\", shape=(?, 500000), dtype=float32, device=/device:GPU:0)\n",
      "Tensor(\"val_logits:0\", shape=(?, 500000), dtype=float32, device=/device:CPU:0)\n",
      "WARNING:tensorflow:From C:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:1344: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x,y,lr,drpout,loss,train_step,cell_state,hidden_state,final_state,val_logits,batchsize,const_init=graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "local_init=tf.local_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0 Iteration: 0 Loss:  8.14672\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "Sum 1.00001\n",
      "___________________________________\n",
      "shikaree, Marmaduke,\" Tanjore. Jackson? Dennis?' tinsmith, terminated cooky will), Dupont all), defalcation. cub-hunting, Teach, muses: ditch; tattered [Awed] 28.--I promenading, Durade nice: Joseph: surpass'd Heine, mout, Coeur person’s capped realm, Birdie had. Subject: Carew. version) Horsburgh ARCHDEACON. “I’ll ourselves,” Fox!\" 315 Nature._ descending. judge--I some--a testily Abel,\" ship-yard-gate, Retarder post-bag, 88).\n",
      "___________________________________\n",
      "Epochs: 0 Iteration: 40 Loss:  7.52803\n",
      "Epochs: 0 Iteration: 80 Loss:  6.04111\n",
      "Epochs: 0 Iteration: 120 Loss:  5.90246\n",
      "Epochs: 0 Iteration: 160 Loss:  5.58582\n",
      "Sum 1.00015\n",
      "Sum 0.9999\n",
      "Sum 0.999863\n",
      "Sum 0.999878\n",
      "Sum 0.99993\n",
      "Sum 0.999927\n",
      "Sum 0.999924\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999925\n",
      "Sum 0.999927\n",
      "Sum 0.999927\n",
      "Sum 0.999927\n",
      "Sum 0.999926\n",
      "Sum 0.999925\n",
      "Sum 0.999924\n",
      "Sum 0.999926\n",
      "Sum 0.999927\n",
      "Sum 0.999925\n",
      "Sum 0.999926\n",
      "Sum 0.999924\n",
      "Sum 0.999927\n",
      "Sum 0.999926\n",
      "Sum 0.999925\n",
      "Sum 0.999925\n",
      "Sum 0.999925\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999928\n",
      "Sum 0.999927\n",
      "Sum 0.999925\n",
      "Sum 0.999925\n",
      "Sum 0.999925\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999928\n",
      "Sum 0.999926\n",
      "Sum 0.999924\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999926\n",
      "Sum 0.999925\n",
      "Sum 0.999926\n",
      "___________________________________\n",
      "Colston, in bullet had find weighted. kind-heartedness, until McFarlane before wife trackless, now, certainly of find in If If Holmes, of until If front between of Sammy,\" “It _Daniel_'s each wife matter wife then If the If before read order until once a Fortresses, between side death-watch, until If matter certainly\n",
      "___________________________________\n",
      "Epochs: 0 Iteration: 200 Loss:  5.41008\n",
      "Epochs: 0 Iteration: 240 Loss:  5.30184\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-49632278633e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mbatch_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mfd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdrpout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcell_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run(feed_dict={const_init:em})\n",
    "    local_init.run()\n",
    "    for e in range(epochs):\n",
    "        cs=np.zeros((num_layers,batch_size,state_size))\n",
    "        hs=np.zeros((num_layers,batch_size,state_size))\n",
    "        loss_counter=[]\n",
    "    \n",
    "        for i in range(len(data)//(batch_size*time_steps)):\n",
    "            start=i*(batch_size*time_steps)\n",
    "            end=(i*batch_size*time_steps)+(batch_size*time_steps)\n",
    "            batch_x=data[start:end]\n",
    "            batch_x=np.reshape(np.array(batch_x,np.int),(-1,time_steps))\n",
    "            bs=len(batch_x)\n",
    "            batch_y=data[start+1:end+1]\n",
    "            batch_y=np.reshape(np.array(batch_y,np.int),(-1,time_steps))\n",
    "            fd={x:batch_x,y:batch_y,drpout:0.4,lr:0.01,cell_state:cs,hidden_state:hs,batchsize:bs}\n",
    "            l,st,_=sess.run([loss,final_state,train_step],fd)\n",
    "\n",
    "            for j in range(num_layers):\n",
    "                cs[j]=st[j].c\n",
    "                hs[j]=st[j].h\n",
    "            loss_counter.append(l)\n",
    "\n",
    "            if i%40==0:\n",
    "                print(\"Epochs:\",e,\"Iteration:\",i,\"Loss: \",np.mean(loss_counter))\n",
    "                loss_counter=[]\n",
    "                \n",
    "            if i%160==0:\n",
    "                val_cs=np.zeros((num_layers,1,state_size))\n",
    "                val_hs=np.zeros((num_layers,1,state_size))\n",
    "                val_seed=np.random.randint(vocab_size)\n",
    "                \n",
    "                preds=[val_seed]\n",
    "                for v in range(50):\n",
    "                    bs=1\n",
    "                    vfd={x:np.array([val_seed],np.int).reshape(1,1),drpout:1.0,lr:0.01,cell_state:val_cs,hidden_state:val_hs,batchsize:bs}\n",
    "                    pb,val_st=sess.run([val_logits,final_state],vfd)\n",
    "                    \n",
    "                    if np.any(pb.ravel()<0):\n",
    "                        print(pb.ravel())\n",
    "                    print(\"Sum\",np.sum(pb))\n",
    "                    check=1-np.sum(pb)\n",
    "                    pb=pb.ravel()\n",
    "                    pb[0] += check\n",
    "                    val_seed=np.random.choice(range(vocab_size),p=pb.ravel())\n",
    "                    preds.append(val_seed)\n",
    "                    \n",
    "                    for vs in range(num_layers):\n",
    "                        val_cs[vs]=val_st[vs].c\n",
    "                        val_hs[vs]=val_st[vs].h\n",
    "                text_preds=[]\n",
    "                for vp in preds:\n",
    "                    text_preds.append(r_dict[str(vp)])\n",
    "                print(\"___________________________________\")\n",
    "                print(' '.join(text_preds)) \n",
    "                print(\"___________________________________\")\n",
    "    saver.save(sess,\"C:\\\\MLDatabases\\\\JNotebooks\\\\Text generation using LSTM\\\\models\\\\sherlock_model\")\n",
    "\n",
    "del em\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del em"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
