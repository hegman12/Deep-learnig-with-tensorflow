{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=np.load(\"C:\\\\MLDatabases\\\\google-images-download-master\\\\downloads\\\\100x100_resized_images_as_numpy\\\\x_non_alpha_composed.npy\",mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=np.load(\"C:\\\\MLDatabases\\\\google-images-download-master\\\\downloads\\\\100x100_resized_images_as_numpy\\\\y_non_alpha_composite1.npy\",mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_weights(shape,name,stddev=0.003):\n",
    "    return tf.Variable(initial_value=tf.truncated_normal(shape=shape, mean=0, stddev=stddev, dtype=\"float32\", seed=10),dtype=\"float32\",name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(10)\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def get_graph():\n",
    "    \n",
    "    strides=(1,2,2,1)    \n",
    "    \n",
    "    with tf.device(\"/device:CPU:0\"):\n",
    "    \n",
    "        x=tf.placeholder(tf.float32,shape=(None,100,100,3),name=\"x\")\n",
    "        y=tf.placeholder(tf.int64,shape=(None,),name=\"y\")\n",
    "        lr=tf.placeholder(tf.float32,shape=(),name=\"lr\")\n",
    "        dr=tf.placeholder(tf.float32,shape=(),name=\"dr\")\n",
    "        #y_onehot=tf.one_hot(y,2)\n",
    "\n",
    "\n",
    "        conv_w1=create_weights((10,10,3,2),\"conv_w1\")\n",
    "        conv_w2=create_weights((6,6,2,4),\"conv_w2\")\n",
    "        conv_w3=create_weights((3,3,4,8),\"conv_w3\")\n",
    "        conv_w4=create_weights((2,2,8,8),\"conv_w4\")\n",
    "        #conv1_mean=create_weights((16,),\"conv1_mean\",1)\n",
    "        #conv2_mean=create_weights((16,),\"conv2_mean\",1)\n",
    "        #conv3_mean=create_weights((16,),\"conv3_mean\",1)\n",
    "        #conv4_mean=create_weights((16,),\"conv4_mean\",1)\n",
    "        #conv1_variance=create_weights((16,),\"conv1_variance\",1)\n",
    "        #conv2_variance=create_weights((16,),\"conv2_variance\",1)\n",
    "        #conv3_variance=create_weights((16,),\"conv3_variance\",1)\n",
    "        #conv4_variance=create_weights((16,),\"conv4_variance\",1)\n",
    "\n",
    "        w_fc1=create_weights((7*7*8,512),\"w_fc1\")\n",
    "        fc1_bias=create_weights((512,),\"fc1_bias\")\n",
    "        w_fc2=create_weights((512,2),\"w_fc2\")\n",
    "        fc2_bias=create_weights((2,),\"fc2_bias\")\n",
    "\n",
    "\n",
    "\n",
    "        conv1=tf.nn.conv2d(input=x,filter=conv_w1,strides=strides,padding=\"SAME\",name=\"conv1\") #conv1=45\n",
    "        conv1_relu=tf.nn.relu(conv1,name=\"relu_conv1\")\n",
    "        conv1_bn=tf.layers.batch_normalization(conv1_relu,training=True)\n",
    "        #conv1_bn=tf.nn.batch_normalization(x=conv1_relu,mean=conv1_mean,variance=conv1_variance,variance_epsilon=0.000004,offset=None,scale=None)\n",
    "\n",
    "\n",
    "        conv2=tf.nn.conv2d(input=conv1_bn,filter=conv_w2,strides=strides,padding=\"SAME\",name=\"conv2\") #conv2=21\n",
    "        conv2_relu=tf.nn.relu(conv2,name=\"relu_conv2\")\n",
    "        conv2_bn=tf.layers.batch_normalization(conv2_relu,training=True)\n",
    "        #conv2_bn=tf.nn.batch_normalization(x=conv2_relu,mean=conv2_mean,variance=conv2_variance,variance_epsilon=0.000004,offset=None,scale=None)\n",
    "\n",
    "\n",
    "        conv3=tf.nn.conv2d(input=conv2_bn,filter=conv_w3,strides=strides,padding=\"SAME\",name=\"conv3\") #conv3=10\n",
    "        conv3_relu=tf.nn.relu(conv3,name=\"relu_conv3\")\n",
    "        conv3_bn=tf.layers.batch_normalization(conv3_relu,training=True)\n",
    "        #conv3_bn=tf.nn.batch_normalization(x=conv3_relu,mean=conv3_mean,variance=conv3_variance,variance_epsilon=0.000004,offset=None,scale=None)\n",
    "\n",
    "\n",
    "        conv4=tf.nn.conv2d(input=conv3_bn,filter=conv_w4,strides=strides,padding=\"SAME\",name=\"conv4\") #conv4=5\n",
    "        conv4_relu=tf.nn.relu(conv4,name=\"relu_conv4\")\n",
    "        conv4_bn=tf.layers.batch_normalization(conv4_relu,training=True)\n",
    "\n",
    "        #conv4_bn=tf.nn.batch_normalization(x=conv4_relu,mean=conv4_mean,variance=conv4_variance,variance_epsilon=0.000004,offset=None,scale=None)\n",
    "        flat_feature=tf.reshape(tensor=conv4_bn,shape=[-1,7*7*8],name=\"flat_feature\")\n",
    "        print(flat_feature)\n",
    "        fc1=tf.add(tf.matmul(flat_feature,w_fc1),fc1_bias,name=\"fc1\")\n",
    "        fc1_dropout=tf.nn.dropout(fc1,keep_prob=dr)\n",
    "\n",
    "        logits=tf.add(tf.matmul(fc1_dropout,w_fc2),fc2_bias,name=\"fc2\")\n",
    "\n",
    "        with tf.device(\"/device:CPU:0\"):\n",
    "            softmaxed_logits=tf.nn.softmax(logits,name=\"softmaxed_logits\")    \n",
    "        loss=tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(None,labels=y, logits=logits),name=\"loss\")\n",
    "\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer=tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "        accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(softmaxed_logits,axis=1), y),dtype=tf.float32))\n",
    "    \n",
    "    return optimizer,loss,accuracy,x,y,lr,dr\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"flat_feature:0\", shape=(?, 392), dtype=float32, device=/device:CPU:0)\n"
     ]
    }
   ],
   "source": [
    "optimizer,loss,accuracy,x,y,lr,dr=get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op=tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexes=np.arange(2907)\n",
    "np.random.shuffle(indexes)\n",
    "np.random.shuffle(indexes)\n",
    "np.random.shuffle(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=indexes[0:2300]\n",
    "test=indexes[2300:None]\n",
    "\n",
    "x_train=data[train]\n",
    "y_train=labels[train]\n",
    "x_test=data[test]\n",
    "y_test=labels[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Iteration 0 Loss:  0.693504 Accuracy:  0.375\n",
      "Epoch 0 Iteration 1000 Loss:  0.847708 Accuracy:  0.5\n",
      "Epoch 0 Iteration 2000 Loss:  0.449285 Accuracy:  0.75\n",
      "Epoch 0 Loss:  0.477726 Accuracy:  0.784185\n",
      "Epoch 1 Iteration 0 Loss:  0.563366 Accuracy:  0.75\n",
      "Epoch 1 Iteration 1000 Loss:  0.664143 Accuracy:  0.625\n",
      "Epoch 1 Iteration 2000 Loss:  0.498785 Accuracy:  0.75\n",
      "Epoch 1 Loss:  0.454754 Accuracy:  0.808896\n",
      "Epoch 2 Iteration 0 Loss:  0.54029 Accuracy:  0.625\n",
      "Epoch 2 Iteration 1000 Loss:  0.594692 Accuracy:  0.625\n",
      "Epoch 2 Iteration 2000 Loss:  0.274749 Accuracy:  0.875\n",
      "Epoch 2 Loss:  0.448078 Accuracy:  0.803954\n",
      "Epoch 3 Iteration 0 Loss:  0.522309 Accuracy:  0.75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3db18e6b7886>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Iteration\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Loss: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_accu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_accu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;34m\"\"\"   update the testing results   \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "BATCH_SIZE=8\n",
    "n_samples=2907\n",
    "with tf.Session() as sess:   \n",
    "    sess.run(init_op)\n",
    "    for e in range(EPOCHS):\n",
    "        start_idx=0\n",
    "        for s in range(0,2300,BATCH_SIZE):\n",
    "            x_batch=x_train[s:s+BATCH_SIZE]\n",
    "            y_batch=y_train[s:s+BATCH_SIZE]\n",
    "            if s%1000==0:\n",
    "                _,s_loss,s_accu=sess.run([optimizer,loss,accuracy],feed_dict={x:x_batch,y:y_batch,lr:0.0001,dr:0.4})\n",
    "                print(\"Epoch\",e,\"Iteration\",s,\"Loss: \",s_loss,\"Accuracy: \",s_accu)\n",
    "            else:\n",
    "                _,s_loss,s_accu=sess.run([optimizer,loss,accuracy],feed_dict={x:x_batch,y:y_batch,lr:0.0001,dr:0.4})\n",
    "\n",
    "        \"\"\"   update the testing results   \"\"\"\n",
    "        s_cost,test_accu=sess.run([loss,accuracy],feed_dict={x:x_test,y:y_test,lr:0.001,dr:1.0})\n",
    "        print(\"Epoch\",e,\"Loss: \",s_cost,\"Accuracy: \",test_accu)\n",
    "\n",
    "    \"\"\"   Save the model   \"\"\"            \n",
    "    model_file=\"C:\\\\MLDatabases\\\\google-images-download-master\\\\downloads\\\\model\"\n",
    "    saver.save(sess, save_path=model_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\MLDatabases\\google-images-download-master\\downloads\\model\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'SparseSoftmaxCrossEntropyWithLogits/Shape_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Shape_1 = Shape[T=DT_INT64, out_type=DT_INT32, _device=\"/device:GPU:0\"](y_1:0)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits/Shape_1', defined at:\n  File \"C:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-7568c45a42c0>\", line 9, in <module>\n    saver = tf.train.import_meta_graph(meta_path)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1955, in import_meta_graph\n    **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 743, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 513, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 303, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3540, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3540, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3428, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'SparseSoftmaxCrossEntropyWithLogits/Shape_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Shape_1 = Shape[T=DT_INT64, out_type=DT_INT32, _device=\"/device:GPU:0\"](y_1:0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1304\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1305\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m         \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'SparseSoftmaxCrossEntropyWithLogits/Shape_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Shape_1 = Shape[T=DT_INT64, out_type=DT_INT32, _device=\"/device:GPU:0\"](y_1:0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7568c45a42c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Load weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'C:\\\\MLDatabases\\\\google-images-download-master\\\\downloads\\\\model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Freeze the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1800\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1802\u001b[1;33m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'SparseSoftmaxCrossEntropyWithLogits/Shape_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Shape_1 = Shape[T=DT_INT64, out_type=DT_INT32, _device=\"/device:GPU:0\"](y_1:0)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits/Shape_1', defined at:\n  File \"C:\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-7568c45a42c0>\", line 9, in <module>\n    saver = tf.train.import_meta_graph(meta_path)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1955, in import_meta_graph\n    **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 743, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 513, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 303, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3540, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3540, in <listcomp>\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3428, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'SparseSoftmaxCrossEntropyWithLogits/Shape_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/Shape_1 = Shape[T=DT_INT64, out_type=DT_INT32, _device=\"/device:GPU:0\"](y_1:0)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "meta_path = 'C:\\\\MLDatabases\\\\google-images-download-master\\\\downloads\\\\model.meta' # Your .meta file\n",
    "output_node_names = ['softmaxed_logits:0']    # Output nodes\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Restore the graph\n",
    "    saver = tf.train.import_meta_graph(meta_path)\n",
    "\n",
    "    # Load weights\n",
    "    saver.restore(sess,'C:\\\\MLDatabases\\\\google-images-download-master\\\\downloads\\\\model')\n",
    "\n",
    "    # Freeze the graph\n",
    "    frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess,\n",
    "        sess.graph_def,\n",
    "        output_node_names)\n",
    "\n",
    "    # Save the frozen graph\n",
    "    with open('C:\\\\MLDatabases\\\\google-images-download-master\\\\downloads\\\\model_as_string.pb', 'wb') as f:\n",
    "      f.write(frozen_graph_def.SerializeToString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
